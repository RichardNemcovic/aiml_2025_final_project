---
tags:
- sentence-transformers
- sentence-similarity
- feature-extraction
- generated_from_trainer
- dataset_size:15112
- loss:ContrastiveLoss
base_model: sentence-transformers/all-MiniLM-L6-v2
widget:
- source_sentence: 'Is 2024/2025BA-BSTHO1023U  Sustainable Tourism Supply and

    Innovation a mandatory or elective course?'
  sentences:
  - '2024/2025BA-BHAAI1003U  Undergraduate Consumer Behavior and

    Customer Analysis is a Obligatorisk course.'
  - '2025/2026KAN-CKOMO2007U  Transformationens politik -

    samfundstendenser og ledelse i organisationer is a 7,5 ECTS ECTS course.'
  - '2024/2025BA-BSTHO1023U  Sustainable Tourism Supply and

    Innovation is a Obligatorisk course.'
- source_sentence: 'What is the description of 2024/2025DIP-DHDVV8003U  Coaching –
    et værktøj i

    ledelseskassen?'
  sentences:
  - 2024/2025MA-MMBDV2104U  Project Leadership is a Bachelor level course.
  - '2024/2025

    BA-BEBUO1018U  Virksomhedsstrategi i et

    netværksperspektiv

    English Title

    Corporate Strategy in a Network

    Perspective

    Kursusinformation

    Sprog

    Dansk

    Kursets ECTS

    7,5 ECTS

    Type

    Obligatorisk

    Niveau

    Bachelor

    Varighed

    Et quarter

    Starttidspunkt

    Forår

    Tidspunkt

    Skemaet bliver offentliggjort på

    calendar.cbs.dk

    Studienævn

    Studienævnet for HA i europæisk business

    Kursusansvarlig

    Christoph Houman Ellersgaard - Institut for Organisation

    (IOA)

    (Lasse Folke

    Henriksen er delvis fagansvarlig)

    Primære

    fagområder

    Organisation/Organisation

    Sociologi/Sociology

    Strategi/Strategy

    Undervisningsformer

    Tilstedeværelsesundervisning

    Sidst opdateret den

    17-06-2024

    Relevante links

    Studieordninger

    Eksamensregler

    Læringsmål

    Redegøre for forskellige forståelser af virksomhedsstrategi i

    netværksperspektiv

    Analysere intra- og interorganisatoriske netværk ved brug af

    teori og metode fra netværksanalyse

    Vurdere og kritisk reflektere over den strategiske betydning af

    virksomheder og deres medarbejderes placering i sociale, økonomiske

    og politiske netværk

    Anvende teorier og metode fra netværksanalyse til at forstå,

    hvorfor og hvordan virksomhedsinterne netværk indvirker på

    medarbejdernes og virksomhedens strategiske handlerum

    Præsentere eksempler på succesrige og fejlslagne

    virksomhedsstrategier ud fra et netværksanalytisk

    perspektiv

    Forudsætninger for at deltage i kurset

    Grundlæggende kendskab til R, fx fra kursus i

    Statistics på 3. semester af HA EB

    Prøve/delprøver

    Virksomhedsstrategi i et

    netværksperspektiv:

    Prøvens

    ECTS

    7,5

    Prøveform

    Skriftligt produkt udarbejdet hjemme

    Individuel eller gruppeprøve

    Gruppeprøve

    Bemærk studieordningens bestemmelser om krav om

    individualisering af opgavebesvarelsen.

    Antal personer i gruppen

    2-5

    Omfang af skriftligt produkt

    Max. 10 sider

    Afleveres på baggrund af udleveret case og

    data

    Opgavetype

    Essay

    Udlevering af opgave

    Opgaven stilles i undervisningen

    Varighed

    Skriftligt produkt afleveres på en fastsat dato

    og tidspunkt.

    Bedømmelsesform

    7-trins-skala

    Bedømmer(e)

    En eksaminator

    Eksamensperiode

    Sommer

    Syge-/omprøve

    Samme prøveform som ved ordinær prøve

    Hvis et gruppemedlem rammes af

    sygdom kan gruppens opgave genbruges

    Beskrivelse af

    eksamensforløbet

    Ved semesterstart udleveres et eksamensspørgsmål, som de

    studerende kan arbejde med løbende i løbet af

    kurset

    Kursets indhold, forløb og pædagogik

    Formål: Kurset introducerer til virksomhedsstrategi i et

    netværksperspektiv. Virksomheder og deres medarbejdere er afhængige

    af deres omverden og en helt central måde er at knytte an til

    omverdenen gennem netværk af forskellig art. Virksomheder

    konkurrerer og samarbejder med andre organisationer via netværk,

    som bl.a. giver dem adgang til resurser, som de er afhængige af.

    Kurset udstyrer de studerende med teoretiske og metodiske redskaber

    fra den netværksanalytiske tradition til at forstå hvordan interne

    såvel som eksterne netværk indvirker på virksomhedens strategiske

    processer.

    Kurset er inddelt i tre dele.

    Første

    del giver

    en introduktion til forskellige teorier om ’virksomhedsstrategi i

    netværksperspektiv’ og eksemplificerer teorierne gennem brug af

    cases.

    Anden

    del indfører de studerende i

    metodiske redskaber fra netværksanalysen.

    Tredje

    del har fokus på anvendelse af netværksanalyse på konkrete cases og

    giver de studerende mulighed for at lave en konkret netværksanalyse

    af et intra- eller inter-organisatorisk netværk. Forbindelsen

    mellem teori og metode i konkrete caseanalyser har prioritet

    ligesom de praktisk-strategiske implikationer af virksomhedsnetværk

    løbende vil blive diskuteret gennem kurset.

    Beskrivelse af undervisningsformer

    Undervisningen er en kombination af forelæsninger

    og øvelseshold. Der vil også være adgang til videoforelæsninger og

    video guides til kodning i R.

    Feedback i undervisningen

    De studerende modtager feedback i øvelsestimerne.

    Her vil vi arbejde med networksdata og de studerende vil få løbende

    sparring og feedback på deres arbejde.

    Studenterarbejdstimer

    Deltagelse

    36 timer

    Forberedelse

    126 timer

    Eksamen

    168 timer

    Foreløbig litteratur

    Burt, R. (1983).

    Corporate Profits and Cooptation: Networks

    of Market Constraint and Directorate Ties in the American

    Economy

    . New York: Academic Press.

    Burt, R. (1992).

    Structural Holes: The Social Structure of

    Competition

    . Cambridge, MA: Harvard University

    Press.

    Davis, G. F., Yoo, M., & Baker, W. E. (2003). “The small

    world of the American corporate elite, 1982-2001.”

    Strategic

    Organization

    ,

    1

    (3), 301–26.

    Fligstein, N. (2001).

    The Architecture of Markets

    .

    Princeton: Princeton University Press.

    Granovetter, M. (1985). “Economic Action and Social Structure:

    The Problem of Embeddedness.”

    American Journal of

    Sociology

    ,

    91

    (3), 481–510.

    Henriksen, L. and C. Waldstrøm. 2016. Netværksanalyse - en

    introduktion. Kbh.: Samfundslitteratur.

    Podolny, J. (1993). “A Status-Based Model of Market

    Competition.”

    American Journal of Sociology

    ,

    98

    (4), 829–72.

    Powell, W., Koput, K. W., & Smith-Doerr, L. (1996).

    “Interorganizational collaboration and the locus of innovation:

    Networks of learning in biotechnology.”

    Administrative science

    quarterly

    ,

    41

    (1), 116–145.

    Vedres, D., & Stark, D. (2010). “Structural Folds:

    Generative Disruption in Overlapping Groups.”

    American Journal

    of Sociology

    ,

    115

    (4), 1150–90.

    Vitali, S., Glattfelder, J. B., & Battiston, S. (2011). “The

    network of global corporate control.”

    PLoS

    ONE

    ,

    6

    (10). General Finance; Physics and

    Society.

    Westphal, J. D. (1999). “Collaboration in the boardroom: The

    consequences of social ties in the CEO/board relationship.”

    Academy of Management Journal

    ,

    42

    (1),

    7–24.

    White, H. (1981). “Where Do Markets Come From?”

    American

    Journal of Sociology

    ,

    87

    (3), 517–47.

    Uzzi, B. (1997). “Social Structure and Competition in Inter-Firm

    Networks: The Paradox of Embeddedness.”

    Administrative Science

    Quarterly

    ,

    42

    (1), 35–67.

    Uzzi, B., & Spiro, J. (2005). “Collaboration and Creativity:

    The Small World Problem.”

    American Journal of Sociology

    ,

    111

    (2), 447–504.

    Sidst opdateret den

    17-06-2024'
  - 2024/2025KAN-CMIAO1007U  Business Project is taught in English.
- source_sentence: 'What level is the course 2024/2025KAN-CACAO1008U  Risk Management
    and Corporate

    Finance?'
  sentences:
  - '2024/2025KAN-CACAO1008U  Risk Management and Corporate

    Finance is a Bachelor level course.'
  - 2024/2025BA-BMAKO3004U  Regnskab is a Diplom level course.
  - 2024/2025BA-BHAAV1016U  Quantitative Methods is a Bachelor level course.
- source_sentence: 'What language is 2024/2025KAN-CCMVI2116U  The Changing Nature
    of Work: Towards a

    Digital Future taught in?'
  sentences:
  - 2024/2025KAN-CCMVV4061U  Cases in Corporate Finance is a Full Degree Master level
    course.
  - 2024/2025BA-BPROO1004U  Organisationsteori is a Obligatorisk course.
  - '2024/2025KAN-CCMVI2116U  The Changing Nature of Work: Towards a

    Digital Future is taught in English.'
- source_sentence: 'What level is the course 2024/2025KAN-CEADV2401U  Introduction
    to Machine Learning for

    Economics?'
  sentences:
  - 2024/2025BA-BINBV1106U  Danish – Integrated Skills is taught in English.
  - '2024/2025KAN-CEADV2401U  Introduction to Machine Learning for

    Economics is a Bachelor level course.'
  - '2025/2026KAN-CKOMV2502U  Interpersonel kommunikation i

    erhvervslivet: Bliv hørt (og hør selv efter) is a Bachelor level course.'
pipeline_tag: sentence-similarity
library_name: sentence-transformers
---

# SentenceTransformer based on sentence-transformers/all-MiniLM-L6-v2

This is a [sentence-transformers](https://www.SBERT.net) model finetuned from [sentence-transformers/all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2). It maps sentences & paragraphs to a 384-dimensional dense vector space and can be used for semantic textual similarity, semantic search, paraphrase mining, text classification, clustering, and more.

## Model Details

### Model Description
- **Model Type:** Sentence Transformer
- **Base model:** [sentence-transformers/all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) <!-- at revision c9745ed1d9f207416be6d2e6f8de32d1f16199bf -->
- **Maximum Sequence Length:** 512 tokens
- **Output Dimensionality:** 384 dimensions
- **Similarity Function:** Cosine Similarity
<!-- - **Training Dataset:** Unknown -->
<!-- - **Language:** Unknown -->
<!-- - **License:** Unknown -->

### Model Sources

- **Documentation:** [Sentence Transformers Documentation](https://sbert.net)
- **Repository:** [Sentence Transformers on GitHub](https://github.com/UKPLab/sentence-transformers)
- **Hugging Face:** [Sentence Transformers on Hugging Face](https://huggingface.co/models?library=sentence-transformers)

### Full Model Architecture

```
SentenceTransformer(
  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: BertModel 
  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})
)
```

## Usage

### Direct Usage (Sentence Transformers)

First install the Sentence Transformers library:

```bash
pip install -U sentence-transformers
```

Then you can load this model and run inference.
```python
from sentence_transformers import SentenceTransformer

# Download from the 🤗 Hub
model = SentenceTransformer("sentence_transformers_model_id")
# Run inference
sentences = [
    'What level is the course 2024/2025KAN-CEADV2401U\xa0\xa0Introduction to Machine Learning for\nEconomics?',
    '2024/2025KAN-CEADV2401U\xa0\xa0Introduction to Machine Learning for\nEconomics is a Bachelor level course.',
    '2024/2025BA-BINBV1106U\xa0\xa0Danish – Integrated Skills is taught in English.',
]
embeddings = model.encode(sentences)
print(embeddings.shape)
# [3, 384]

# Get the similarity scores for the embeddings
similarities = model.similarity(embeddings, embeddings)
print(similarities.shape)
# [3, 3]
```

<!--
### Direct Usage (Transformers)

<details><summary>Click to see the direct usage in Transformers</summary>

</details>
-->

<!--
### Downstream Usage (Sentence Transformers)

You can finetune this model on your own dataset.

<details><summary>Click to expand</summary>

</details>
-->

<!--
### Out-of-Scope Use

*List how the model may foreseeably be misused and address what users ought not to do with the model.*
-->

<!--
## Bias, Risks and Limitations

*What are the known or foreseeable issues stemming from this model? You could also flag here known failure cases or weaknesses of the model.*
-->

<!--
### Recommendations

*What are recommendations with respect to the foreseeable issues? For example, filtering explicit content.*
-->

## Training Details

### Training Dataset

#### Unnamed Dataset

* Size: 15,112 training samples
* Columns: <code>sentence_0</code>, <code>sentence_1</code>, and <code>label</code>
* Approximate statistics based on the first 1000 samples:
  |         | sentence_0                                                                         | sentence_1                                                                          | label                                                          |
  |:--------|:-----------------------------------------------------------------------------------|:------------------------------------------------------------------------------------|:---------------------------------------------------------------|
  | type    | string                                                                             | string                                                                              | float                                                          |
  | details | <ul><li>min: 15 tokens</li><li>mean: 28.87 tokens</li><li>max: 67 tokens</li></ul> | <ul><li>min: 2 tokens</li><li>mean: 156.17 tokens</li><li>max: 512 tokens</li></ul> | <ul><li>min: 0.0</li><li>mean: 0.62</li><li>max: 1.0</li></ul> |
* Samples:
  | sentence_0                                                                                                                 | sentence_1                                                                                                      | label            |
  |:---------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------|:-----------------|
  | <code>What is the ECTS value of the course 2024/2025KAN-CJURV1153U  Videregående kontraktret og<br>kontraktøkonomi?</code> | <code>2024/2025KAN-CJURV1153U  Videregående kontraktret og<br>kontraktøkonomi is a 7,5 ECTS ECTS course.</code> | <code>1.0</code> |
  | <code>What level is the course 2024/2025BA-BHAAV2302U  Marketing Communication (Online).?</code>                           | <code>2024/2025BA-BHAAV2302U  Marketing Communication (Online). is a Bachelor level course.</code>              | <code>1.0</code> |
  | <code>Is 2024/2025BA-BDMAO1001U  Managing Innovation in Organizations a mandatory or elective course?</code>               | <code>2024/2025BA-BDMAO1001U  Managing Innovation in Organizations is a Obligatorisk course.</code>             | <code>0.0</code> |
* Loss: [<code>ContrastiveLoss</code>](https://sbert.net/docs/package_reference/sentence_transformer/losses.html#contrastiveloss) with these parameters:
  ```json
  {
      "distance_metric": "SiameseDistanceMetric.COSINE_DISTANCE",
      "margin": 0.5,
      "size_average": true
  }
  ```

### Training Hyperparameters
#### Non-Default Hyperparameters

- `per_device_train_batch_size`: 16
- `per_device_eval_batch_size`: 16
- `multi_dataset_batch_sampler`: round_robin

#### All Hyperparameters
<details><summary>Click to expand</summary>

- `overwrite_output_dir`: False
- `do_predict`: False
- `eval_strategy`: no
- `prediction_loss_only`: True
- `per_device_train_batch_size`: 16
- `per_device_eval_batch_size`: 16
- `per_gpu_train_batch_size`: None
- `per_gpu_eval_batch_size`: None
- `gradient_accumulation_steps`: 1
- `eval_accumulation_steps`: None
- `torch_empty_cache_steps`: None
- `learning_rate`: 5e-05
- `weight_decay`: 0.0
- `adam_beta1`: 0.9
- `adam_beta2`: 0.999
- `adam_epsilon`: 1e-08
- `max_grad_norm`: 1
- `num_train_epochs`: 3
- `max_steps`: -1
- `lr_scheduler_type`: linear
- `lr_scheduler_kwargs`: {}
- `warmup_ratio`: 0.0
- `warmup_steps`: 0
- `log_level`: passive
- `log_level_replica`: warning
- `log_on_each_node`: True
- `logging_nan_inf_filter`: True
- `save_safetensors`: True
- `save_on_each_node`: False
- `save_only_model`: False
- `restore_callback_states_from_checkpoint`: False
- `no_cuda`: False
- `use_cpu`: False
- `use_mps_device`: False
- `seed`: 42
- `data_seed`: None
- `jit_mode_eval`: False
- `use_ipex`: False
- `bf16`: False
- `fp16`: False
- `fp16_opt_level`: O1
- `half_precision_backend`: auto
- `bf16_full_eval`: False
- `fp16_full_eval`: False
- `tf32`: None
- `local_rank`: 0
- `ddp_backend`: None
- `tpu_num_cores`: None
- `tpu_metrics_debug`: False
- `debug`: []
- `dataloader_drop_last`: False
- `dataloader_num_workers`: 0
- `dataloader_prefetch_factor`: None
- `past_index`: -1
- `disable_tqdm`: False
- `remove_unused_columns`: True
- `label_names`: None
- `load_best_model_at_end`: False
- `ignore_data_skip`: False
- `fsdp`: []
- `fsdp_min_num_params`: 0
- `fsdp_config`: {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}
- `tp_size`: 0
- `fsdp_transformer_layer_cls_to_wrap`: None
- `accelerator_config`: {'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None}
- `deepspeed`: None
- `label_smoothing_factor`: 0.0
- `optim`: adamw_torch
- `optim_args`: None
- `adafactor`: False
- `group_by_length`: False
- `length_column_name`: length
- `ddp_find_unused_parameters`: None
- `ddp_bucket_cap_mb`: None
- `ddp_broadcast_buffers`: False
- `dataloader_pin_memory`: True
- `dataloader_persistent_workers`: False
- `skip_memory_metrics`: True
- `use_legacy_prediction_loop`: False
- `push_to_hub`: False
- `resume_from_checkpoint`: None
- `hub_model_id`: None
- `hub_strategy`: every_save
- `hub_private_repo`: None
- `hub_always_push`: False
- `gradient_checkpointing`: False
- `gradient_checkpointing_kwargs`: None
- `include_inputs_for_metrics`: False
- `include_for_metrics`: []
- `eval_do_concat_batches`: True
- `fp16_backend`: auto
- `push_to_hub_model_id`: None
- `push_to_hub_organization`: None
- `mp_parameters`: 
- `auto_find_batch_size`: False
- `full_determinism`: False
- `torchdynamo`: None
- `ray_scope`: last
- `ddp_timeout`: 1800
- `torch_compile`: False
- `torch_compile_backend`: None
- `torch_compile_mode`: None
- `include_tokens_per_second`: False
- `include_num_input_tokens_seen`: False
- `neftune_noise_alpha`: None
- `optim_target_modules`: None
- `batch_eval_metrics`: False
- `eval_on_start`: False
- `use_liger_kernel`: False
- `eval_use_gather_object`: False
- `average_tokens_across_devices`: False
- `prompts`: None
- `batch_sampler`: batch_sampler
- `multi_dataset_batch_sampler`: round_robin

</details>

### Training Logs
| Epoch  | Step | Training Loss |
|:------:|:----:|:-------------:|
| 0.5291 | 500  | 0.0112        |
| 1.0582 | 1000 | 0.0033        |
| 1.5873 | 1500 | 0.002         |
| 2.1164 | 2000 | 0.0013        |
| 2.6455 | 2500 | 0.001         |


### Framework Versions
- Python: 3.11.12
- Sentence Transformers: 3.4.1
- Transformers: 4.51.3
- PyTorch: 2.6.0+cu124
- Accelerate: 1.6.0
- Datasets: 3.5.1
- Tokenizers: 0.21.1

## Citation

### BibTeX

#### Sentence Transformers
```bibtex
@inproceedings{reimers-2019-sentence-bert,
    title = "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks",
    author = "Reimers, Nils and Gurevych, Iryna",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
    month = "11",
    year = "2019",
    publisher = "Association for Computational Linguistics",
    url = "https://arxiv.org/abs/1908.10084",
}
```

#### ContrastiveLoss
```bibtex
@inproceedings{hadsell2006dimensionality,
    author={Hadsell, R. and Chopra, S. and LeCun, Y.},
    booktitle={2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)},
    title={Dimensionality Reduction by Learning an Invariant Mapping},
    year={2006},
    volume={2},
    number={},
    pages={1735-1742},
    doi={10.1109/CVPR.2006.100}
}
```

<!--
## Glossary

*Clearly define terms in order to be accessible across audiences.*
-->

<!--
## Model Card Authors

*Lists the people who create the model card, providing recognition and accountability for the detailed work that goes into its construction.*
-->

<!--
## Model Card Contact

*Provides a way for people who have updates to the Model Card, suggestions, or questions, to contact the Model Card authors.*
-->