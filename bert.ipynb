{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9bAt2wt9cSm"
      },
      "source": [
        "**AI & Machine Learning (KAN-CINTO4003U) - Copenhagen Business School | Spring 2025**\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJ5kFtoS9cSp"
      },
      "source": [
        "\n",
        "# Part II: BERT\n",
        "\n",
        "Please see the description of the assignment in the README file (section 2) <br>\n",
        "**Guide notebook**: [guides/bert_guide.ipynb](guides/bert_guide.ipynb)\n",
        "\n",
        "\n",
        "***\n",
        "\n",
        "<br>\n",
        "\n",
        "* Note that you should report results using a classification report.\n",
        "\n",
        "* Also, remember to include some reflections on your results: how do they compare with the results from Part I, BoW? Are there any hyperparameters that are particularly important?\n",
        "\n",
        "* You should follow the steps given in the `bert_guide` notebook\n",
        "\n",
        "* **Optionally**, you can fine-tune a pre-trained BERT model to classify news articles as is done in [guides/bert_guide_finetuning.ipybb](guides/bert_guide_finetuning.ipybb), the same task as in part 1. As this requires more computational resources, this part is optional. If you do decide to complete this part, you will need to use a GPU (e.g., Google Colab) to train the model. (For reference, training on a 2020 Macbook Pro with 16GB RAM and a M1 chip results in an out-of-memory error). Therefore, we suggest that you use Google Colab or another cloud-based service with a GPU. You can easily upload the `bert_guide_finetuning.ipynb` notebook to Google Colab and run it there.\n",
        "\n",
        "<br>\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJRGRcYZAQOt"
      },
      "source": [
        "#Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: evaluate in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from evaluate) (3.5.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\richard nemcovic\\appdata\\roaming\\python\\python311\\site-packages (from evaluate) (2.2.5)\n",
            "Requirement already satisfied: dill in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from evaluate) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from evaluate) (2.32.2)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in c:\\users\\richard nemcovic\\appdata\\roaming\\python\\python311\\site-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from evaluate) (0.30.2)\n",
            "Requirement already satisfied: packaging in c:\\users\\richard nemcovic\\appdata\\roaming\\python\\python311\\site-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from datasets>=2.0.0->evaluate) (20.0.0)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.11.18)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.0)\n",
            "Requirement already satisfied: idna>=2.0 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets>=2.0.0->evaluate) (3.10)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
            "Requirement already satisfied: colorama in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Requirement already satisfied: sentence-transformers==2.2.2 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (2.2.2)\n",
            "Requirement already satisfied: transformers==4.31.0 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (4.31.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from sentence-transformers==2.2.2) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from sentence-transformers==2.2.2) (2.7.0)\n",
            "Requirement already satisfied: torchvision in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from sentence-transformers==2.2.2) (0.22.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\richard nemcovic\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers==2.2.2) (2.2.5)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from sentence-transformers==2.2.2) (1.6.1)\n",
            "Requirement already satisfied: scipy in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from sentence-transformers==2.2.2) (1.15.2)\n",
            "Requirement already satisfied: nltk in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from sentence-transformers==2.2.2) (3.9.1)\n",
            "Requirement already satisfied: sentencepiece in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from sentence-transformers==2.2.2) (0.2.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from sentence-transformers==2.2.2) (0.30.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from transformers==4.31.0) (3.18.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\richard nemcovic\\appdata\\roaming\\python\\python311\\site-packages (from transformers==4.31.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from transformers==4.31.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from transformers==4.31.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from transformers==4.31.0) (2.32.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from transformers==4.31.0) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from transformers==4.31.0) (0.5.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.13.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from sympy>=1.13.3->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from tqdm->sentence-transformers==2.2.2) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (3.0.2)\n",
            "Requirement already satisfied: click in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from nltk->sentence-transformers==2.2.2) (8.1.8)\n",
            "Requirement already satisfied: joblib in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from nltk->sentence-transformers==2.2.2) (1.4.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from requests->transformers==4.31.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from requests->transformers==4.31.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from requests->transformers==4.31.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from requests->transformers==4.31.0) (2025.1.31)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from scikit-learn->sentence-transformers==2.2.2) (3.6.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from torchvision->sentence-transformers==2.2.2) (11.1.0)\n",
            "Requirement already satisfied: torch in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (2.7.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting huggingface_hub==0.16.4\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from huggingface_hub==0.16.4) (3.18.0)\n",
            "Requirement already satisfied: fsspec in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from huggingface_hub==0.16.4) (2025.3.0)\n",
            "Requirement already satisfied: requests in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from huggingface_hub==0.16.4) (2.32.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from huggingface_hub==0.16.4) (4.67.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from huggingface_hub==0.16.4) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from huggingface_hub==0.16.4) (4.13.2)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\richard nemcovic\\appdata\\roaming\\python\\python311\\site-packages (from huggingface_hub==0.16.4) (24.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub==0.16.4) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from requests->huggingface_hub==0.16.4) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from requests->huggingface_hub==0.16.4) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from requests->huggingface_hub==0.16.4) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\richard nemcovic\\.conda\\envs\\aiml_2025_final_project\\lib\\site-packages (from requests->huggingface_hub==0.16.4) (2025.1.31)\n",
            "Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "Installing collected packages: huggingface_hub\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.30.2\n",
            "    Uninstalling huggingface-hub-0.30.2:\n",
            "      Successfully uninstalled huggingface-hub-0.30.2\n",
            "Successfully installed huggingface_hub-0.16.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 3.5.1 requires huggingface-hub>=0.24.0, but you have huggingface-hub 0.16.4 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "!pip install "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmZK9KLPAQtN"
      },
      "source": [
        "# Imports for the project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWIst4Wj9cSq"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from datasets import Dataset, DatasetDict\n",
        "from langchain_core.documents import Document\n",
        "from sentence_transformers import InputExample, SentenceTransformer, SentencesDataset, losses, models\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoTokenizer, pipeline, TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpqfTep49cSs"
      },
      "source": [
        "### 1. Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 1643 chunks.\n"
          ]
        }
      ],
      "source": [
        "# Load structured CBS knowledge base\n",
        "df = pd.read_csv(\"data/cbs_graduate_programs.csv\")\n",
        "\n",
        "# Prepare LangChain Document objects with metadata\n",
        "chunks = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    metadata = {\n",
        "        \"url\": row[\"url\"],\n",
        "        \"section_title\": row[\"section_title\"],\n",
        "        \"section_type\": row[\"section_type\"],\n",
        "        \"page_name\": row[\"page_name\"]\n",
        "    }\n",
        "    text = \"page_name: \" + row[\"page_name\"] + \"text: \" + row[\"text_chunk\"]\n",
        "    chunks.append(Document(page_content=text, metadata=metadata))\n",
        "\n",
        "print(f\"Loaded {len(chunks)} chunks.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Train-test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "THsX_9UYAj37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'url', 'section_title', 'section_type', 'page_name'],\n",
            "        num_rows: 1314\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'url', 'section_title', 'section_type', 'page_name'],\n",
            "        num_rows: 329\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# Convert LangChain Documents into dict format\n",
        "data = [{\n",
        "    \"text\": str(doc.page_content) if doc.page_content else \"\",\n",
        "    \"url\": str(doc.metadata.get(\"url\", \"\")),\n",
        "    \"section_title\": str(doc.metadata.get(\"section_title\", \"\")),\n",
        "    \"section_type\": str(doc.metadata.get(\"section_type\", \"\")),\n",
        "    \"page_name\": str(doc.metadata.get(\"page_name\", \"\"))\n",
        "} for doc in chunks]\n",
        "\n",
        "# Train-test split (80/20)\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to HuggingFace Dataset\n",
        "train_dataset = Dataset.from_list(train_data)\n",
        "test_dataset = Dataset.from_list(test_data)\n",
        "cbs_dataset = DatasetDict({\"train\": train_dataset, \"test\": test_dataset})\n",
        "\n",
        "# Inspect\n",
        "print(cbs_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "page_name_to_chunks = defaultdict(list)\n",
        "for item in cbs_dataset[\"train\"]:\n",
        "    page_name_to_chunks[item[\"page_name\"]].append(item)\n",
        "\n",
        "# Create positive and negative pairs\n",
        "train_examples = []\n",
        "\n",
        "for page_name, group in page_name_to_chunks.items():\n",
        "    # Positive pairs (within same page)\n",
        "    for i in range(len(group)):\n",
        "        for j in range(i + 1, len(group)):\n",
        "            train_examples.append(InputExample(texts=[group[i], group[j]], label=1.0))\n",
        "\n",
        "    # Sample negative examples (pair with random chunk from other page)\n",
        "    negatives = [t for k, v in page_name_to_chunks.items() if k != page_name for t in v]\n",
        "    for _ in range(min(3, len(group))):  # limit to avoid too many negatives\n",
        "        anchor = random.choice(group)\n",
        "        negative = random.choice(negatives)\n",
        "        train_examples.append(InputExample(texts=[anchor, negative], label=0.0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4dfa5eba92844a7bba1c6dcf28f452b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Richard Nemcovic\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d844361535d4cb6afaeefe97d1637a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d467f5bb0d1c4679ae6e38c9e6ad3309",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b183e9ad1d594c6da21b537f854654a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60857116774e452c9ef87480bcb12f5b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load ModernBERT as a sentence transformer model\n",
        "word_embedding_model = models.Transformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
        "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8c3f64340804ef5be99d4c95681d349",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "718cfe1b529149f3b29850f6fb89bef0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Iteration:   0%|          | 0/857 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m train_dataloader = DataLoader(train_examples, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, batch_size=\u001b[32m16\u001b[39m)\n\u001b[32m      2\u001b[39m train_loss = losses.CosineSimilarityLoss(model)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_objectives\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# Increase if needed\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:721\u001b[39m, in \u001b[36mSentenceTransformer.fit\u001b[39m\u001b[34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[39m\n\u001b[32m    719\u001b[39m     skip_scheduler = scaler.get_scale() != scale_before_step\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m721\u001b[39m     loss_value = \u001b[43mloss_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    722\u001b[39m     loss_value.backward()\n\u001b[32m    723\u001b[39m     torch.nn.utils.clip_grad_norm_(loss_model.parameters(), max_grad_norm)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\sentence_transformers\\losses\\CosineSimilarityLoss.py:39\u001b[39m, in \u001b[36mCosineSimilarityLoss.forward\u001b[39m\u001b[34m(self, sentence_features, labels)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, sentence_features: Iterable[Dict[\u001b[38;5;28mstr\u001b[39m, Tensor]], labels: Tensor):\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     embeddings = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence_feature\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msentence_embedding\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msentence_feature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msentence_features\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     40\u001b[39m     output = \u001b[38;5;28mself\u001b[39m.cos_score_transformation(torch.cosine_similarity(embeddings[\u001b[32m0\u001b[39m], embeddings[\u001b[32m1\u001b[39m]))\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loss_fct(output, labels.view(-\u001b[32m1\u001b[39m))\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\sentence_transformers\\losses\\CosineSimilarityLoss.py:39\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, sentence_features: Iterable[Dict[\u001b[38;5;28mstr\u001b[39m, Tensor]], labels: Tensor):\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     embeddings = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence_feature\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m'\u001b[39m\u001b[33msentence_embedding\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m sentence_feature \u001b[38;5;129;01min\u001b[39;00m sentence_features]\n\u001b[32m     40\u001b[39m     output = \u001b[38;5;28mself\u001b[39m.cos_score_transformation(torch.cosine_similarity(embeddings[\u001b[32m0\u001b[39m], embeddings[\u001b[32m1\u001b[39m]))\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.loss_fct(output, labels.view(-\u001b[32m1\u001b[39m))\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\torch\\nn\\modules\\container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:66\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, features)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mtoken_type_ids\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[32m     64\u001b[39m     trans_features[\u001b[33m'\u001b[39m\u001b[33mtoken_type_ids\u001b[39m\u001b[33m'\u001b[39m] = features[\u001b[33m'\u001b[39m\u001b[33mtoken_type_ids\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m output_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m output_tokens = output_states[\u001b[32m0\u001b[39m]\n\u001b[32m     69\u001b[39m features.update({\u001b[33m'\u001b[39m\u001b[33mtoken_embeddings\u001b[39m\u001b[33m'\u001b[39m: output_tokens, \u001b[33m'\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m'\u001b[39m: features[\u001b[33m'\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m'\u001b[39m]})\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1022\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1013\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m   1015\u001b[39m embedding_output = \u001b[38;5;28mself\u001b[39m.embeddings(\n\u001b[32m   1016\u001b[39m     input_ids=input_ids,\n\u001b[32m   1017\u001b[39m     position_ids=position_ids,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1020\u001b[39m     past_key_values_length=past_key_values_length,\n\u001b[32m   1021\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1030\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1034\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1035\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:612\u001b[39m, in \u001b[36mBertEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    603\u001b[39m     layer_outputs = torch.utils.checkpoint.checkpoint(\n\u001b[32m    604\u001b[39m         create_custom_forward(layer_module),\n\u001b[32m    605\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    609\u001b[39m         encoder_attention_mask,\n\u001b[32m    610\u001b[39m     )\n\u001b[32m    611\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m612\u001b[39m     layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    613\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    614\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    615\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    617\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    618\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    623\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:539\u001b[39m, in \u001b[36mBertLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    536\u001b[39m     cross_attn_present_key_value = cross_attention_outputs[-\u001b[32m1\u001b[39m]\n\u001b[32m    537\u001b[39m     present_key_value = present_key_value + cross_attn_present_key_value\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m layer_output = \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    540\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    542\u001b[39m outputs = (layer_output,) + outputs\n\u001b[32m    544\u001b[39m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\transformers\\pytorch_utils.py:239\u001b[39m, in \u001b[36mapply_chunking_to_forward\u001b[39m\u001b[34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[39m\n\u001b[32m    236\u001b[39m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[32m    237\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(output_chunks, dim=chunk_dim)\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:552\u001b[39m, in \u001b[36mBertLayer.feed_forward_chunk\u001b[39m\u001b[34m(self, attention_output)\u001b[39m\n\u001b[32m    550\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[32m    551\u001b[39m     intermediate_output = \u001b[38;5;28mself\u001b[39m.intermediate(attention_output)\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m     layer_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:464\u001b[39m, in \u001b[36mBertOutput.forward\u001b[39m\u001b[34m(self, hidden_states, input_tensor)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.dropout(hidden_states)\n\u001b[32m    466\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.LayerNorm(hidden_states + input_tensor)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Richard Nemcovic\\.conda\\envs\\aiml_2025_final_project\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
        "train_loss = losses.CosineSimilarityLoss(model)\n",
        "\n",
        "model.fit(\n",
        "    train_objectives=[(train_dataloader, train_loss)],\n",
        "    epochs=2,             # Increase if needed\n",
        "    warmup_steps=100,\n",
        "    show_progress_bar=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = SentenceTransformer(\"models/modernbert-cbs-embedding\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-9W2ZVZAs3Q"
      },
      "source": [
        "# Load ModernBERT tokenizer and model from HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCWUi9YOAsjY"
      },
      "outputs": [],
      "source": [
        "# Define the mappping from label names to label ids\n",
        "id2label = {\n",
        "    0: 'World',\n",
        "    1: 'Sports',\n",
        "    2: 'Business',\n",
        "    3: 'Sci/Tech'\n",
        "}\n",
        "\n",
        "# Define the mapping from label ids to label names (the reverse of id2label)\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "\n",
        "# load the model\n",
        "model = ModernBertForSequenceClassification.from_pretrained(\"answerdotai/ModernBERT-base\", num_labels=4, id2label=id2label, label2id=label2id)\n",
        "\n",
        "# load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb8_X_WwA1n8"
      },
      "source": [
        "# Tokenize and encode the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucsDIMrQA3RM"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    \"\"\" Tokenize the text column in the examples. \"\"\"\n",
        "    return tokenizer(examples[\"text\"], truncation=True)\n",
        "\n",
        "tokenized_ag_news = ag_news.map(preprocess_function, batched=True, batch_size=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQiBNj5oA3uH"
      },
      "source": [
        "# Set evaluation metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tc86T7ITA4OE"
      },
      "outputs": [],
      "source": [
        "f1 = evaluate.load(\"f1\")\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    f1 = f1_score(labels, predictions, average='weighted')  # 'weighted' for multiclass\n",
        "    return {\"f1\": f1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGcSRoelBEXt"
      },
      "source": [
        "# Define a data collator and mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ne_Bi_exBFCZ"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDgz3FjJBPVb"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Akn3zuBa9cSu"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/AIML_2025/ma2/my_awesome_model\",  # THIS NEEDS TO CHANGE ON GOOGLE COLAB: \"/content/drive/MyDrive/Colab Notebooks/my_awesome_model\" or similar. Please check the path.\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.025,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_ag_news[\"train\"],\n",
        "    eval_dataset=tokenized_ag_news[\"test\"],\n",
        "    processing_class=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcfoJOOtBX8m"
      },
      "source": [
        "# Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJ3uJ-nfBaAl"
      },
      "outputs": [],
      "source": [
        "train_predictions = trainer.predict(tokenized_ag_news[\"train\"])\n",
        "test_predictions = trainer.predict(tokenized_ag_news[\"test\"])\n",
        "\n",
        "# Extract predictions and labels\n",
        "train_preds, train_labels = train_predictions.predictions.argmax(axis=1), train_predictions.label_ids\n",
        "test_preds, test_labels = test_predictions.predictions.argmax(axis=1), test_predictions.label_ids\n",
        "\n",
        "# Classification report for train dataset\n",
        "print(\"Train Classification Report:\")\n",
        "print(classification_report(train_labels, train_preds))\n",
        "\n",
        "# Classification report for test dataset\n",
        "print(\"Test Classification Report:\")\n",
        "print(classification_report(test_labels, test_preds))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
